{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "anonymous-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import time\n",
    "import numpy as np\n",
    "import threading\n",
    "import pickle\n",
    "import Pdf2Text\n",
    "import heapq\n",
    "theadcount = 0\n",
    "processBagofwords = {}\n",
    "prossesstokenarry =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "distributed-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Theard(root,files,processlock,):\n",
    "    global processBagofwords\n",
    "    global prossesstokenarry\n",
    "    global theadcount\n",
    "    ok =True\n",
    "    theardbagofword = {}\n",
    "    tokenarry = []\n",
    "    try:\n",
    "        for name in files:\n",
    "            bagofword = Pdf2Text.BuildModelToTraing(os.path.join(os.path.join(root, name)), name, processlock,)\n",
    "            theardbagofword =Pdf2Text.margedictionaries(theardbagofword,bagofword[1])\n",
    "            tokenarry.append(bagofword[0])\n",
    "        processlock.acquire()\n",
    "        processBagofwords = Pdf2Text.margedictionaries(processBagofwords,theardbagofword)\n",
    "        prossesstokenarry += tokenarry\n",
    "        theadcount -=1\n",
    "        processlock.release()\n",
    "    except:\n",
    "        processlock.acquire()\n",
    "        theadcount -= 1\n",
    "        processlock.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "collected-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataFromFile(tokentotrain):\n",
    "    traningset = []\n",
    "    file = open(os.path.join(\"File\", \"Bagofwords.txt\"), 'rb')\n",
    "    Bagofwords = pickle.load(file)\n",
    "    file.close()\n",
    "    if(tokentotrain == None ):\n",
    "        file = open(os.path.join(\"File\", \"tokentotrain.txt\"), 'rb')\n",
    "        tokentotrain = pickle.load(file)\n",
    "        file.close()\n",
    "    for file in tokentotrain:\n",
    "        data = file\n",
    "        sent_vec=[]\n",
    "        for word in Bagofwords :\n",
    "                if word in file[2]:\n",
    "                    sent_vec.append(1)\n",
    "                else:\n",
    "                    sent_vec.append(0)\n",
    "        sent_vec = np.asarray(sent_vec)\n",
    "        data.append(sent_vec)\n",
    "        traningset.append(data)\n",
    "    return (Bagofwords,traningset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wicked-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagofwords = {}\n",
    "theadsarry = []\n",
    "tokenarry = []\n",
    "global processBagofwords\n",
    "global prossesstokenarry\n",
    "global theadcount\n",
    "processlock = threading.Lock()\n",
    "allfiles = []\n",
    "for root, directories, files in os.walk(os.path.join(\"File\\here\"), topdown=False):\n",
    "    allfiles+=(files)\n",
    "splitedfilses = np.array_split(allfiles, len(allfiles)/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "color-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "for newfiles in splitedfilses:\n",
    "    t1 = threading.Thread(target=Theard, args=(root, newfiles, processlock,))\n",
    "    theadsarry.append(t1)\n",
    "    theadcount += 1\n",
    "time.sleep(0.5)\n",
    "for t in theadsarry:\n",
    "    t.start()\n",
    "while (theadcount > 0):\n",
    "    if (len(processBagofwords) > 0):\n",
    "        processlock.acquire()\n",
    "        Bagofwords = Pdf2Text.margedictionaries(Bagofwords, processBagofwords)\n",
    "        processBagofwords = {}\n",
    "        processlock.release()\n",
    "    if (len(prossesstokenarry) > 0):\n",
    "        processlock.acquire()\n",
    "        tokenarry += prossesstokenarry\n",
    "        prossesstokenarry = []\n",
    "        processlock.release()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "elementary-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data =GetDataFromFile(tokenarry)[1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "varied-block",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "knowing-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "seeing-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location(enum.IntEnum):\n",
    "    Lable = 0\n",
    "    Root = 1\n",
    "    wordtoken =2\n",
    "    bagofword = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "general-agency",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x00000218D9A78550>\n"
     ]
    }
   ],
   "source": [
    "model= tf.keras.models.load_model('File.model')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "oriented-factor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "לבדיקה\n",
      "דוח שנתי\n",
      "דוח שנתי\n",
      "לבדיקה\n",
      "הצרות הון\n",
      "הצרות הון\n"
     ]
    }
   ],
   "source": [
    "for index,bagofword in enumerate(data):\n",
    "    testing_padded =np.array(bagofword[int(Location.bagofword)]).reshape(1,900)\n",
    "    predict = model.predict(testing_padded)[0]\n",
    "    label= np.argmax(predict)\n",
    "    if predict[0]>0.9 or predict[1]>0.9:\n",
    "        if label == 1:\n",
    "            data[index][int(Location.Lable)] = \"הצרות הון\"\n",
    "        elif label == 0:\n",
    "            data[index][int(Location.Lable)] = \"דוח שנתי\"\n",
    "for i in data:       \n",
    "    print(i[int(Location.Lable)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-dublin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-blackberry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-decline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
